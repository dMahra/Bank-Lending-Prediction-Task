{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6df9637-aae5-46b8-9331-f13b7b3f8cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "darsh_data = pd.read_csv('lending_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75e5f8a8-b5cb-4557-8fb7-d3c7098660db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 25)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darsh_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e720fd3-9426-40fb-b6f7-a8a1bfbb843a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    799870\n",
       "0    200130\n",
       "Name: loan_paid, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darsh_data['loan_paid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "570671b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessv2(data):\n",
    "    di = {'4 years':4,'10+ years':10,'2 years':2,'7 years':7,'8 years':8,'3 years':3,'< 1 year':0.5,'1 year':1,'9 years':9,'5 years':5,'6 years':6}\n",
    "    data = data.replace({\"employment_length\":di})\n",
    "    # make loan_duration numeric\n",
    "    data['loan_duration'] = data['loan_duration'].apply(lambda x: int(x[0:3]))\n",
    "    \n",
    "    data.drop(['employment', 'extended_reason', 'zipcode','ID'],axis=1, inplace=True)\n",
    "\n",
    "    # Select numeric columns.\n",
    "    a = data.select_dtypes('number')\n",
    "    # Select string and object columns.\n",
    "    b = data.select_dtypes('object')\n",
    "\n",
    "    # Fill numeric columns with mean.\n",
    "    data[a.columns] = a.fillna(a.mean())\n",
    "    # Fill object columns with mode.\n",
    "    data[b.columns] = b.fillna(b.agg(lambda x: x.mode().values[0]))\n",
    "    \n",
    "    data['home_ownership_status']=data['home_ownership_status'].replace(['NONE', 'ANY'], 'OTHER')\n",
    "\n",
    "    dummies = pd.get_dummies(data['home_ownership_status'],drop_first=True)\n",
    "    data = data.drop('home_ownership_status',axis=1)\n",
    "    data = pd.concat([data,dummies],axis=1)\n",
    "    \n",
    "    dummies = pd.get_dummies(data[['race', 'reason_for_loan','employment_verified',\n",
    "                                     'type_of_application','state']],drop_first=True)\n",
    "    \n",
    "    data = data.drop(['race', 'reason_for_loan','employment_verified','state',\n",
    "                                         'type_of_application','state'],axis=1)\n",
    "    X = pd.concat([data, dummies],axis=1).drop(columns = ['loan_paid'], axis=1)\n",
    "\n",
    "    return (X, data['loan_paid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "580abc68-a57f-4e78-abd2-27cbed863568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a80acac0-bd18-4f39-a6ef-685318289a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocessv2(darsh_data) #including feature drop off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3e53e92-536a-4313-8f26-c0438a13c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2ba3401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750000, 87)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #training data is 75% of the split while testing is 25% (of sampled 500k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8976b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from collections import Counter\n",
    "# Generate datasets\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.datasets import make_imbalance\n",
    "# Train, test, splits and gridsearch optimization\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Class weights\n",
    "from sklearn.utils import class_weight\n",
    "# Performance\n",
    "from sklearn.metrics import classification_report\n",
    "# Modeling\n",
    "import xgboost\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "697b0a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:40:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.9068,\n",
       "              enable_categorical=False, gamma=5.295, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.3874, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=7.685, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=39, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0.03764, reg_lambda=1,\n",
       "              scale_pos_weight=0.25, subsample=1, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/67303447/how-to-use-downsampling-and-configure-class-weight-parameter-when-using-xgboost\n",
    "from math import sqrt\n",
    "X, y = preprocessv2(darsh_data) #including feature drop off\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=8, stratify=y)\n",
    "# scaled_X, scaled_y = make_imbalance(X, y, sampling_strategy={0:200}, random_state=8)\n",
    "# Get the counts of the training data per XGBoost documentation\n",
    "counts = Counter(y_train)\n",
    "# model_sqrt = xgboost.XGBClassifier(scale_pos_weight=sqrt(counts[0] / counts[1]), random_state=30,\n",
    "#             sample_weight=class_weight.compute_sample_weight(class_weight='balanced', y=scaled_y))\n",
    "\n",
    "# model_sqrt = xgboost.XGBClassifier(scale_pos_weight=sqrt(counts[0] / counts[1]))\n",
    "model_sqrt = xgboost.XGBClassifier(scale_pos_weight= .25)\n",
    "# model_sqrt = xgboost.XGBClassifier(scale_pos_weight=(counts[0] / counts[1]),learning_rate=0.3874,max_depth=5,n_estimators=39,reg_alpha=.03764,min_child_weight = 9)\n",
    "model_sqrt = xgboost.XGBClassifier(scale_pos_weight=.25,learning_rate = 0.3874,max_depth=5,n_estimators=39,reg_alpha=0.03764,colsample_bytree=0.9068,gamma=5.295,min_child_weight=7.685)\n",
    "\n",
    "# ^ mess with hyperparameters here ^\n",
    "model_sqrt.fit(X_train, y_train)\n",
    "# print(classification_report(y_test, model_sqrt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a8e117e-7787-49b0-9f19-af2af391fc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150098 599902\n"
     ]
    }
   ],
   "source": [
    "print(counts[0],counts[1])\n",
    "# ratio of 0 to 1 is ~.25\n",
    "# 0's are negative class 1's are positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab7bcbe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64586"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_sqrt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a915d7b-dd93-4d86-959b-442b2128df4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 31906,  18126],\n",
       "       [ 70409, 129559]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6035245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data_final = pd.read_csv('lending_topredict.csv')\n",
    "final_dat, loan_paid = preprocessv2(testing_data_final)\n",
    "final_pred = model_sqrt.predict(final_dat)\n",
    "df = pd.DataFrame(final_pred)\n",
    "df['ID'] = testing_data_final['ID']\n",
    "df.rename(columns = {0:'loan_paid'}, inplace = True)\n",
    "columns_titles = [\"ID\",\"loan_paid\"]\n",
    "df2=df.reindex(columns=columns_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3148e1b6-f93a-486d-8f98-afd09dacb0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    799870\n",
       "0    200130\n",
       "Name: loan_paid, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "darsh_data['loan_paid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "045ebb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('darsh_predsv16.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "111820f3-87da-47b2-9007-679d6d4378f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "last = pd.read_csv(\"last.csv\")\n",
    "loss = pd.read_csv(\"loss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4ae4b46-e8ae-4343-a85c-00125ba27e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourteen = pd.read_csv(\"darsh_predsv14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "120369fd-126a-424d-9adf-10741cf09333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    201107\n",
       "0    144203\n",
       "Name: loan_paid, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourteen['loan_paid'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
